{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Data Analysis on Covid-19 dataset (India).\n",
    "\n",
    "![corona](https://c.files.bbci.co.uk/14A35/production/_115033548_gettyimages-1226314512.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c2d3e26064dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Input data files are available in the read-only \"../input/\" directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import missingno\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/covid19-in-india/covid_19_india.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **We will be analyzing the data of Covid-19 spread over the Indian states. The data ranges from 01-January-2020 to 26-November-2020.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:8835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the missing values in the dataset using missingno package and info of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking duplicated values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are looking for unique timestamps given in the dataset, further we will merge the ***date*** and the ***time*** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\"Date\" : \"Datetime\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Datetime column to dtype of datetime64[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeconv(df):\n",
    "    alltime = []\n",
    "    for i in df[\"Time\"]:\n",
    "        mer = i[-2:]\n",
    "        \n",
    "        time = i[:-3]\n",
    "        if len(time) ==4:\n",
    "            time = \"0\"+time\n",
    "        if mer == \"PM\":\n",
    "            time = str(12+int(time[:2]))+time[-3:]\n",
    "        alltime.append(time)\n",
    "    assert df.shape[0] == len(alltime)\n",
    "    df['Datetime'] = df['Datetime'] +\" \"+ pd.Series(alltime)\n",
    "            \n",
    "       \n",
    "        \n",
    "        \n",
    "timeconv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"Time\"],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timest = data.iloc[-2][\"Datetime\"]\n",
    "data.iloc[-1,0] = timest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We discovered that there are several missing values marked as \"-\", let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = data.groupby('State/UnionTerritory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"-\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoa! most of the values are missing in 3rd and 4th column, we better drop those columns for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(list(data.columns)[2:4],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving forward, let's take a look at distinct state names for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['State/UnionTerritory'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping it simple, we will drop the rows with state name ending with \"***\" as it is seems to be rows with incomplete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_star(df):\n",
    "    for i in df['State/UnionTerritory'].iteritems():\n",
    "        if i[1][-3:] == \"***\":\n",
    "            df.drop(i[0],inplace=True)\n",
    "        \n",
    "drop_star(data)\n",
    "data['State/UnionTerritory'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are still several typos in state names, we will deal with this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[(data['State/UnionTerritory']=='Telangana')|(data['State/UnionTerritory']=='Daman & Diu')|(data['State/UnionTerritory']=='Dadar Nagar Haveli')].index,inplace=True)\n",
    "data['State/UnionTerritory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['State/UnionTerritory']=='Tripura']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the latest insights from the data, we will later visualize the trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = data.groupby('State/UnionTerritory')\n",
    "current = l.last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a bar plot to show the spread of Covid-19 across the states in decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax = plt.subplots(figsize= (12,8))\n",
    "fig.set_facecolor(\"white\")\n",
    "current = current.sort_values(\"Confirmed\",ascending=False)\n",
    "p = sns.barplot(ax=ax,x= current.index,y=current['Confirmed'])\n",
    "p.set_xticklabels(labels = current.index,rotation=90)\n",
    "\n",
    "p.set_yticklabels(labels=(p.get_yticks()*1).astype(int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's look at the Cured/Death ratio of these states using pie plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(12,3, figsize=(16,30))\n",
    "fig.delaxes(axs[11,2])\n",
    "fig.set_facecolor(\"white\")\n",
    "def plotpie(ax,cplot,data,state):\n",
    "    labels = ['Cured', 'Deaths','Ambiguous']\n",
    "    colors = ['green', 'red','gray']\n",
    "    amb = data.loc[state]['Confirmed'] - data.loc[state]['Cured']+data.loc[state]['Deaths']\n",
    "    size = [data.loc[state]['Cured'],data.loc[state]['Deaths'],amb]\n",
    "    x = cplot//3\n",
    "    y = cplot%3\n",
    "    ax[x,y].pie(size,labels=labels, colors=colors, startangle=0, autopct='%1.1f%%')\n",
    "    ax[x,y].set_title(state+'\\n'+\"Total cases : {}\".format(data.loc[state]['Confirmed']))\n",
    "    ax[x,y].axis('equal')\n",
    "\n",
    "cplot = 0\n",
    "for i in sorted(list(current.index)):\n",
    "    if i in ['Cases being reassigned to states', 'Unassigned'] :\n",
    "        continue\n",
    "    plotpie(axs,cplot,current,i)\n",
    "    cplot+=1\n",
    "fig.tight_layout()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zooming to the span of 21 days lockdown from 25-March-2020. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "fig, axs = plt.subplots(18,2, figsize=(16,100))\n",
    "fig.set_facecolor(\"white\")\n",
    "fig.delaxes(axs[17,1])\n",
    "\n",
    "def statewise_timeplot(ax,cplot,data,state):\n",
    "    toplot = data[data[\"State/UnionTerritory\"] == state]\n",
    "    x = cplot//2\n",
    "    y = cplot%2\n",
    "    sd = pd.to_datetime('2020-3-25') \n",
    "    td = datetime.timedelta(days=21)\n",
    "    ed = sd+td\n",
    "    #print(sd,ed)\n",
    "    \n",
    "    #toplot = toplot.set_index(\"Datetime\")\n",
    "    toplot = toplot.loc[(toplot[\"Datetime\"] > sd) & (toplot['Datetime']< ed)]\n",
    "    #print(toplot)\n",
    "    toplot = toplot.set_index(\"Datetime\")\n",
    "    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Confirmed\"],ax= ax[x,y],label='Confirmed')\n",
    "    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Cured\"],ax= ax[x,y],label=\"Cured\")\n",
    "    sns.lineplot(data=toplot,x=toplot.index,y=toplot[\"Deaths\"],ax= ax[x,y],label=\"Deaths\")\n",
    "    ax[x,y].set_title(state)\n",
    "    ax[x,y].set_xlim(pd.Timestamp('2020-3-25'),pd.Timestamp(\"2020-04-11\"))\n",
    "    ax[x,y].set_ylim(0,1000000)\n",
    "    ax[x,y].xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    ax[x,y].xaxis.set_minor_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    ax[x,y].tick_params(axis='x', rotation=45)\n",
    "    ax[x,y].legend()\n",
    "\n",
    "\n",
    "\n",
    "cplot = 0\n",
    "for i in sorted(list(current.index)):\n",
    "    if i in ['Cases being reassigned to states', 'Unassigned'] :\n",
    "        continue\n",
    "    statewise_timeplot(axs,cplot,data,i)\n",
    "    cplot+=1\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepariing data for geoplot using geopandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"/kaggle/input/india-states/Igismap/Indian_States.shp\"\n",
    "map_df = gpd.read_file(fp)\n",
    "display(map_df)\n",
    "current\n",
    "current.rename(index={\"Andaman and Nicobar Islands\":\"Andaman & Nicobar Island\",\"Delhi\":\"NCT of Delhi\",\"Arunachal Pradesh\":\"Arunanchal Pradesh\",\"Dadra and Nagar Haveli and Daman and Diu\":\"Dadara & Nagar Havelli\",\"Jammu and Kashmir\":\"Jammu & Kashmir\",\"Telengana\":\"Telangana\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current.drop(['Cases being reassigned to states', 'Unassigned'], axis = 0).reset_index()\n",
    "merged = map_df.merge(current, left_on = 'st_nm', right_on = 'State/UnionTerritory', how = 'left')\n",
    "merged = merged[~merged['Datetime'].isna()]\n",
    "merged.reset_index().drop('index', axis = 1)\n",
    "merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, here is the geoplot showing the Covid-19 spread across the Indian states with severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "ax.axis('off')\n",
    "ax.set_title('Covi19 data', fontdict={'fontsize': '25', 'fontweight' : '10'})\n",
    "\n",
    "merged.plot(column='Confirmed',cmap='YlOrRd', linewidth=0.8, ax=ax, edgecolor='0', legend=True,markersize=[39.739192, -104.990337])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
